name: Weekly updates for symbols

on:
  workflow_dispatch:
  schedule:
    # weekly, Monday
    - cron: '0 0 * * 1'
  push:
    paths:
      # on new manual mapping added
      - 'python/tex_to_typ.yaml'
jobs:
  check-typst-symbol-page:
    if: ${{ github.event_name != 'push' }}
    runs-on: ubuntu-slim
    outputs:
      should_run: ${{ steps.check.outputs.changed }}
    permissions:
      contents: write
    env:
      GH_TOKEN: ${{ secrets.PAT_TOKEN }} # Required for 'gh variable set'
      TARGET_URL: "https://typst.app/docs/reference/symbols/sym/"
      GH_REPO: ${{ github.repository }}
      VAR_NAME: "TYPST_ETAG"
    steps:
      - name: Check ETag and Update
        id: check
        shell: bash
        run: |
          CURRENT_ETAG=$(curl -I -s "$TARGET_URL" | grep -i "^etag:" | sed 's/etag: //I' | tr -d '\r')

          if [ -z "$CURRENT_ETAG" ]; then
            echo "::error::Could not fetch ETag. Exiting."
            exit 1
          fi

          STORED_ETAG=$(gh variable get "$VAR_NAME" --json value -q .value 2>/dev/null || echo "")

          echo "Stored:  '$STORED_ETAG'"
          echo "Current: '$CURRENT_ETAG'"

          if [ "$CURRENT_ETAG" != "$STORED_ETAG" ]; then
            echo "changed=true" >> "$GITHUB_OUTPUT"
            echo "âš¡ ETag changed from '$STORED_ETAG' to '$CURRENT_ETAG'"
            gh variable set "$VAR_NAME" --body "$CURRENT_ETAG"
          else
            echo "changed=false" >> "$GITHUB_OUTPUT"
            echo "ðŸ˜´ No change detected."
          fi

  gen-info:
    needs: check-typst-symbol-page
    if: ${{ !failure() && (needs.check-typst-symbol-page.outputs.should_run == 'true' || github.event_name == 'push') }}
    name: dataset-update
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5

      - name: Setup uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true

      - name: Run Generation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "ETag changed. Generating data."
          uv run --no-project --with 'typer' --with 'msgspec' --with 'datasets' --with 'polars' --with 'beautifulsoup4' --with 'lxml' --python 3.13 python/proc_data.py --upload

      - name: Cache Hugging Face datasets
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: huggingface-datasets-${{ hashFiles('python/tex_to_typ.yaml') }}
          restore-keys: |
            huggingface-datasets-

      - name: Upload Data Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: generated-data
          path: |
            build/data/infer.json
            build/data/contrib.json

  trigger-training:
    needs: gen-info
    runs-on: ubuntu-latest
    env:
      TITLE: "Detypify Auto Training"
      KAGGLE_API_TOKEN: ${{ secrets.KAGGLE_KEY }}
    steps:
      - uses: actions/checkout@v5

      - name: Download Data Artifacts
        uses: actions/download-artifact@v4
        with:
          name: generated-data
          path: build/data

      - name: Set up Notebook Kernel
        shell: bash
        env:
          REPO_URL: "https://github.com/${{ github.repository }}"
          BRANCH_NAME: ${{ github.ref_name }}
        run: |
          python -m pip install --upgrade kaggle --user
          OUTPUT_NOTEBOOK="script.ipynb"

          # Notice the escaped variables (\$) in the third block so GitHub Actions doesn't pre-evaluate them
          cat <<EOM > "$OUTPUT_NOTEBOOK"
          {
            "cells": [
              {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "outputs": [],
                "source": [
                  "!git clone --branch $BRANCH_NAME $REPO_URL.git detypify"
                ]
              },
              {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "outputs": [],
                "source": [
                  "!cd detypify && pip install uv && uv --quiet sync && uv run python/train.py"
                ]
              },
              {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "outputs": [],
                "source": [
                  "!for f in detypify/build/train/*/version_*/ckpts/*.onnx; do model=\$(echo \$f | cut -d/ -f4); cp \$f /kaggle/working/\$model.onnx && echo \"Copied \$f -> /kaggle/working/\$model.onnx\"; done"
                ]
              }
            ],
            "metadata": {
              "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
              },
              "language_info": {
                "name": "python",
                "version": "3.13"
              }
            },
            "nbformat": 4,
            "nbformat_minor": 2
          }
          EOM

      - name: Push Kernel
        shell: bash
        run: |
          kaggle kernels init -p .

          KAGGLE_USERNAME=$(jq -r '.id' kernel-metadata.json | cut -d'/' -f1)

          KERNEL_SLUG=$(echo "$TITLE" | tr '[:upper:]' '[:lower:]' | sed 's/ /-/g')
          KERNEL_ID="$KAGGLE_USERNAME/$KERNEL_SLUG"

          echo "KERNEL_ID=$KERNEL_ID" >> $GITHUB_ENV

          jq --arg id "$KERNEL_ID" \
             --arg title "$TITLE" \
             --arg code_file "script.ipynb" \
             '.id = $id | .title = $title | .code_file = $code_file | .language = "python" | .kernel_type = "notebook" | .enable_gpu = true | .enable_internet = true' \
             kernel-metadata.json > kernel-metadata.json.tmp && mv kernel-metadata.json.tmp kernel-metadata.json

          cat kernel-metadata.json

          # 6. Push the kernel
          kaggle kernels push -p . --accelerator 'NvidiaTeslaT4'

      - name: Check status
        shell: bash
        run: |
          echo "Checking status for $KERNEL_ID..."

          MAX_RETRIES=240
          COUNT=0

          while [ $COUNT -lt $MAX_RETRIES ]; do
              status=$(kaggle kernels status "$KERNEL_ID" 2>&1)
              echo "Status: $status"

              if [[ "$status" == *"ERROR"* || "$status" == *"CANCEL"* ]]; then
                  echo "::error::Kernel execution failed."
                  exit 1
              elif [[ "$status" == *"COMPLETE"* ]]; then
                  echo "Kernel execution completed successfully!"
                  exit 0
              fi

              sleep 60
              COUNT=$((COUNT+1))
          done

          echo "::error::Kernel execution timed out after 4 hours."
          exit 1

      - name: Download artifacts
        shell: bash
        run: |
          mkdir -p artifacts
          # Use the exact KERNEL_ID (owner/slug) that Kaggle CLI expects
          kaggle kernels output "$KERNEL_ID" -p artifacts
      - name: Upload Trained Models to GitHub
        uses: actions/upload-artifact@v4
        with:
          name: trained-onnx-models
          path: artifacts/build/train
